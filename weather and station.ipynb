{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"smaller_station_data.pickle\",\"rb\")\n",
    "station_weather = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1218"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(station_weather.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(filename):\n",
    "    \n",
    "    maxT = 0\n",
    "    minT = 0\n",
    "    avgP = 0\n",
    "    max_counter = 1\n",
    "    min_counter = 1\n",
    "    precip_counter = 1\n",
    "    #year = []\n",
    "    for i in range(0,len(station_weather[filename])):\n",
    "        element = station_weather[filename].iloc[i].ELEMENT\n",
    "        #if station_weather[filename].iloc[i].YEAR not in year:\n",
    "            #year.append(station_weather[filename].iloc[i].YEAR)\n",
    "        if element == \"TMAX\":\n",
    "            for j in range(1,32):\n",
    "                value=\"VALUE\"+str(j)\n",
    "                if station_weather[filename].iloc[i][value] == -9999:\n",
    "                    max_counter +=1\n",
    "                elif station_weather[filename].iloc[i][value] > maxT:\n",
    "                    maxT = station_weather[filename].iloc[i][value]\n",
    "        elif element == \"TMIN\":\n",
    "            for j in range(1,32):\n",
    "                value=\"VALUE\"+str(j)\n",
    "                if station_weather[filename].iloc[i][value] == -9999:\n",
    "                    min_counter +=1\n",
    "                elif station_weather[filename].iloc[i][value] < minT:\n",
    "                    minT = station_weather[filename].iloc[i][value]\n",
    "        elif element == \"PRCP\":\n",
    "            for j in range(1,32):\n",
    "                value=\"VALUE\"+str(j)\n",
    "                if station_weather[filename].iloc[i][value] == -9999:\n",
    "                    precip_counter +=1\n",
    "                else:\n",
    "                    avgP += station_weather[filename].iloc[i][value]\n",
    "    \n",
    "        avgP = avgP/(31) #tenths of mm\n",
    "\n",
    "    maxT = maxT/10 #tenths of deg C\n",
    "    minT = minT/10 #tenths of deg C\n",
    "    return maxT, minT, avgP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = station_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = df_station.drop(columns=[\"ELEV\",\"ST\",\"NAME\",\"?\",\"GSN\",\"HCN\",\"WMOID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station[\"LAT\"] = df_station[\"LAT\"].apply(lambda x: round(x,1))\n",
    "df_station[\"LON\"] = df_station[\"LON\"].apply(lambda x: round(x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxT_df = df_station.drop(columns=\"LON\")\n",
    "minT_df = df_station.drop(columns=\"LON\")\n",
    "precip_df = df_station.drop(columns=\"LON\")\n",
    "maxT_df = maxT_df.rename(columns={\"LAT\":\"maxT\"})\n",
    "minT_df = minT_df.rename(columns={\"LAT\":\"minT\"})\n",
    "precip_df = precip_df.rename(columns={\"LAT\":\"precip\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxT_list = []\n",
    "minT_list = []\n",
    "precip_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0,len(df_station)):\n",
    "    station = df_station.iloc[i].ID\n",
    "    filename = \"./ghcnd_hcn/ghcnd_hcn/\"+station+\".dly\"\n",
    "    values = get_values(filename)\n",
    "    maxT_list.append(values[0])\n",
    "    minT_list.append(values[1])\n",
    "    precip_list.append(values[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('maxT.pickle', 'wb') as f:\n",
    "    pickle.dump(maxT_list, f)\n",
    "with open('minT.pickle', 'wb') as f:\n",
    "    pickle.dump(minT_list, f)\n",
    "with open('precip.pickle', 'wb') as f:\n",
    "    pickle.dump(precip_list, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxT_df[\"maxT\"]=maxT_list\n",
    "minT_df[\"minT\"]=minT_list\n",
    "precip_df[\"precip\"]=precip_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                  ID  minT\n",
       "0       USW00094008 -35.6\n",
       "92086   USC00011084  -9.4\n",
       "92147   USC00012813  -8.3\n",
       "92162   USC00013160 -12.2\n",
       "92172   USC00013511 -11.1\n",
       "...             ...   ...\n",
       "118603  USW00094224  -5.0\n",
       "118635  USW00094728 -17.2\n",
       "118645  USW00094793   0.0\n",
       "118646  USW00094794 -29.4\n",
       "118691  USW00094967 -42.8\n",
       "\n",
       "[1218 rows x 2 columns]>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minT_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = pd.merge(df_station,maxT_df)\n",
    "df_station = pd.merge(df_station,minT_df)\n",
    "df_station = pd.merge(df_station,precip_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                ID   LAT    LON  maxT  minT     precip\n",
       "0     USW00094008  48.2 -106.6  40.6 -35.6   0.003256\n",
       "1     USC00011084  31.1  -87.1  38.9  -9.4   0.030446\n",
       "2     USC00012813  30.5  -87.9  38.9  -8.3  32.033145\n",
       "3     USC00013160  32.8  -88.1  39.4 -12.2  32.032769\n",
       "4     USC00013511  32.7  -87.6  40.0 -11.1  15.322608\n",
       "...           ...   ...    ...   ...   ...        ...\n",
       "1213  USW00094224  46.2 -123.9  35.6  -5.0   0.122420\n",
       "1214  USW00094728  40.8  -74.0  39.4 -17.2   0.039206\n",
       "1215  USW00094793  41.2  -71.6   0.0   0.0   0.000000\n",
       "1216  USW00094794  43.1  -75.4  36.1 -29.4   0.016112\n",
       "1217  USW00094967  46.9  -95.1  36.1 -42.8   0.003122\n",
       "\n",
       "[1218 rows x 6 columns]>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_station.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('combined.pickle', 'wb') as f:\n",
    "    pickle.dump(df_station, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_weather[\"./ghcnd_hcn/ghcnd_hcn/USC00404561.dly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"hcn_stations.pickle\",\"rb\")\n",
    "station_info = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_station.to_csv(\"combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, StructField, StructType, DoubleType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (pyspark.sql.SparkSession.builder.getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"_c0\",IntegerType(),True),\n",
    "                    StructField(\"ID\", StringType(), True),\n",
    "                     StructField(\"LAT\", DoubleType(), True),\n",
    "                     StructField(\"LON\", DoubleType(), True),\n",
    "                     StructField(\"maxT\", DoubleType(), True),\n",
    "                     StructField(\"minT\", DoubleType(), True),\n",
    "                     StructField(\"precip\", DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = spark.read.csv(\"combined.csv\",header=\"true\",schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- maxT: double (nullable = true)\n",
      " |-- minT: double (nullable = true)\n",
      " |-- precip: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----+------+----+-----+--------------------+\n",
      "|_c0|         ID| LAT|   LON|maxT| minT|              precip|\n",
      "+---+-----------+----+------+----+-----+--------------------+\n",
      "|  0|USW00094008|48.2|-106.6|40.6|-35.6|0.003256017105458339|\n",
      "|  1|USC00011084|31.1| -87.1|38.9| -9.4|0.030446342453921964|\n",
      "|  2|USC00012813|30.5| -87.9|38.9| -8.3|   32.03314489020785|\n",
      "|  3|USC00013160|32.8| -88.1|39.4|-12.2|   32.03276915252046|\n",
      "|  4|USC00013511|32.7| -87.6|40.0|-11.1|  15.322607766248499|\n",
      "+---+-----------+----+------+----+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
